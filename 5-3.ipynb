{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33f10abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "my_list = [['a', 1, 2], ['b', 2, 3],['c', 3, 4]]\n",
    "col_name = ['A', 'B', 'C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5be6081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+\n",
      "|  A|  B|  C|\n",
      "+---+---+---+\n",
      "|  a|  1|  2|\n",
      "|  b|  2|  3|\n",
      "|  c|  3|  4|\n",
      "+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# caution for the columns=\n",
    "pd.DataFrame(my_list,columns= col_name)\n",
    "#\n",
    "spark.createDataFrame(my_list, col_name).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11d947c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'A': [0, 1, 0],\n",
    "     'B': [1, 0, 1],\n",
    "     'C': [1, 0, 0]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "446f8c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+\n",
      "|  A|  B|  C|\n",
      "+---+---+---+\n",
      "|  0|  1|  1|\n",
      "|  1|  0|  0|\n",
      "|  0|  1|  0|\n",
      "+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(d)\n",
    "# Tedious for PySpark\n",
    "spark.createDataFrame(np.array(list(d.values())).T.tolist(),list(d.keys())).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "513fbd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User information is ready!\n"
     ]
    }
   ],
   "source": [
    "#User Information\n",
    "try:\n",
    "    login = pd.read_csv(r'login.txt', header=None)\n",
    "    user = login[0][0]\n",
    "    pw = login[0][1]\n",
    "    print('User information is ready!')\n",
    "except:\n",
    "    print('Login information is not available!!!')\n",
    "\n",
    "#Database information\n",
    "host = 'localhost'\n",
    "db_name = 'db_name'\n",
    "table_name = 'table_name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "563afaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in ./opt/anaconda3/lib/python3.9/site-packages (2.9.5)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0288de51",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "dp = pd.read_json(\"/Users/yangsejin/Downloads/data.json\")\n",
    "ds = spark.read.json('/Users/yangsejin/Downloads/data.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "daf775d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+\n",
      "|         id|          timestamp|\n",
      "+-----------+-------------------+\n",
      "|14785418146|2023-04-02 10:39:01|\n",
      "|14785418136|2023-04-02 10:39:01|\n",
      "|14785418135|2023-04-02 10:39:01|\n",
      "|14785418133|2023-04-02 10:39:01|\n",
      "+-----------+-------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dp[['id','timestamp']].head(4)\n",
    "#\n",
    "ds[['id','timestamp']].show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "825be511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------------+--------------------+--------------------+-------------------+\n",
      "|         id|            location|sampling_rate|              sensor|    sensordatavalues|          timestamp|\n",
      "+-----------+--------------------+-------------+--------------------+--------------------+-------------------+\n",
      "|14785418146|{18.4, NL, 1, 413...|         null|{55464, 7, {9, va...|[{33201110167, 8....|2023-04-02 10:39:01|\n",
      "|14785418136|{116.0, PL, 0, 66...|         null|{77152, 1, {14, N...|[{33201110139, 3....|2023-04-02 10:39:01|\n",
      "|14785418135|{444.5, DE, 0, 29...|         null|{40502, 11, {17, ...|[{33201110132, 15...|2023-04-02 10:39:01|\n",
      "|14785418133|{227.4, PL, 0, 10...|         null|{20966, 1, {14, N...|[{33201110136, 9....|2023-04-02 10:39:01|\n",
      "+-----------+--------------------+-------------+--------------------+--------------------+-------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dp.head(4)\n",
    "#\n",
    "ds.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b153d719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'location', 'sampling_rate', 'sensor', 'sensordatavalues', 'timestamp']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.columns\n",
    "#\n",
    "ds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2dddd3ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'bigint'),\n",
       " ('location',\n",
       "  'struct<altitude:string,country:string,exact_location:bigint,id:bigint,indoor:bigint,latitude:string,longitude:string>'),\n",
       " ('sampling_rate', 'bigint'),\n",
       " ('sensor',\n",
       "  'struct<id:bigint,pin:string,sensor_type:struct<id:bigint,manufacturer:string,name:string>>'),\n",
       " ('sensordatavalues',\n",
       "  'array<struct<id:bigint,value:string,value_type:string>>'),\n",
       " ('timestamp', 'string')]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.dtypes\n",
    "#\n",
    "ds.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0e648c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----+\n",
      "|     A|  B|   C|\n",
      "+------+---+----+\n",
      "|  male|  1|null|\n",
      "|female|  2|   3|\n",
      "|  male|  3|   4|\n",
      "+------+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_list = [['male', 1, None], ['female', 2, 3],['male', 3, 4]]\n",
    "dp = pd.DataFrame(my_list,columns=['A', 'B', 'C'])\n",
    "ds = spark.createDataFrame(my_list, ['A', 'B', 'C'])\n",
    "#\n",
    "dp.head()\n",
    "ds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6f31ffbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+---+\n",
      "|     A|  B|  C|\n",
      "+------+---+---+\n",
      "|  male|  1|-99|\n",
      "|female|  2|  3|\n",
      "|  male|  3|  4|\n",
      "+------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dp.fillna(-99)\n",
    "#\n",
    "ds.fillna(-99).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "05b60113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+\n",
      "|  A|  B|   C|\n",
      "+---+---+----+\n",
      "|  1|  1|null|\n",
      "|  0|  2|   3|\n",
      "|  1|  3|   4|\n",
      "+---+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# caution: you need to chose specific col\n",
    "dp.A.replace(['male', 'female'],[1, 0], inplace=True)\n",
    "dp\n",
    "#caution: Mixed type replacements are not supported\n",
    "ds.na.replace(['male','female'],['1','0']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "02b6168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = pd.read_json(\"/Users/yangsejin/Downloads/data.json\")\n",
    "ds = spark.read.json('/Users/yangsejin/Downloads/data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5452c0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+----+--------------------+--------------------+-------------------+\n",
      "|          a|                   b|   c|                   d|                   e|                  f|\n",
      "+-----------+--------------------+----+--------------------+--------------------+-------------------+\n",
      "|14785418146|{18.4, NL, 1, 413...|null|{55464, 7, {9, va...|[{33201110167, 8....|2023-04-02 10:39:01|\n",
      "|14785418136|{116.0, PL, 0, 66...|null|{77152, 1, {14, N...|[{33201110139, 3....|2023-04-02 10:39:01|\n",
      "|14785418135|{444.5, DE, 0, 29...|null|{40502, 11, {17, ...|[{33201110132, 15...|2023-04-02 10:39:01|\n",
      "|14785418133|{227.4, PL, 0, 10...|null|{20966, 1, {14, N...|[{33201110136, 9....|2023-04-02 10:39:01|\n",
      "|14785418130|{110.6, RS, 0, 41...|null|{55718, 1, {14, N...|[{33201110131, 0....|2023-04-02 10:39:01|\n",
      "|14785418129|{32.5, NL, 0, 545...|null|{67751, 1, {14, N...|[{33201110128, 12...|2023-04-02 10:39:01|\n",
      "+-----------+--------------------+----+--------------------+--------------------+-------------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dp.columns = ['a','b','c','d','e','f']\n",
    "dp.head(6)\n",
    "#\n",
    "ds.toDF('a','b','c','d','e','f').show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4249ecf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'Newspaper':'C','Sales':'D'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8c25e8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------------+--------------------+--------------------+-------------------+\n",
      "|         id|            location|sampling_rate|              sensor|    sensordatavalues|          timestamp|\n",
      "+-----------+--------------------+-------------+--------------------+--------------------+-------------------+\n",
      "|14785418146|{18.4, NL, 1, 413...|         null|{55464, 7, {9, va...|[{33201110167, 8....|2023-04-02 10:39:01|\n",
      "|14785418136|{116.0, PL, 0, 66...|         null|{77152, 1, {14, N...|[{33201110139, 3....|2023-04-02 10:39:01|\n",
      "|14785418135|{444.5, DE, 0, 29...|         null|{40502, 11, {17, ...|[{33201110132, 15...|2023-04-02 10:39:01|\n",
      "|14785418133|{227.4, PL, 0, 10...|         null|{20966, 1, {14, N...|[{33201110136, 9....|2023-04-02 10:39:01|\n",
      "+-----------+--------------------+-------------+--------------------+--------------------+-------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dp.rename(columns=mapping).head(4)\n",
    "#\n",
    "new_names = [mapping.get(col,col) for col in ds.columns]\n",
    "ds.toDF(*new_names).show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "19f8e418",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_name = ['Newspaper','Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "21910142",
   "metadata": {},
   "outputs": [],
   "source": [
    "leftp = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                    'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "                    'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                    'D': ['D0', 'D1', 'D2', 'D3']},\n",
    "                    index=[0, 1, 2, 3])\n",
    "\n",
    "rightp = pd.DataFrame({'A': ['A0', 'A1', 'A6', 'A7'],\n",
    "                       'F': ['B4', 'B5', 'B6', 'B7'],\n",
    "                       'G': ['C4', 'C5', 'C6', 'C7'],\n",
    "                       'H': ['D4', 'D5', 'D6', 'D7']},\n",
    "                       index=[4, 5, 6, 7])\n",
    "\n",
    "lefts = spark.createDataFrame(leftp)\n",
    "rights = spark.createDataFrame(rightp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0b601730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+----+----+----+\n",
      "|  A|  B|  C|  D|   F|   G|   H|\n",
      "+---+---+---+---+----+----+----+\n",
      "| A0| B0| C0| D0|  B4|  C4|  D4|\n",
      "| A1| B1| C1| D1|  B5|  C5|  D5|\n",
      "| A2| B2| C2| D2|null|null|null|\n",
      "| A3| B3| C3| D3|null|null|null|\n",
      "+---+---+---+---+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "leftp.merge(rightp,on='A',how='left')\n",
    "#\n",
    "lefts.join(rights,on='A',how='left').orderBy('A',ascending=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d9db0281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----+----+---+---+---+\n",
      "|  A|   B|   C|   D|  F|  G|  H|\n",
      "+---+----+----+----+---+---+---+\n",
      "| A0|  B0|  C0|  D0| B4| C4| D4|\n",
      "| A1|  B1|  C1|  D1| B5| C5| D5|\n",
      "| A6|null|null|null| B6| C6| D6|\n",
      "| A7|null|null|null| B7| C7| D7|\n",
      "+---+----+----+----+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "leftp.merge(rightp,on='A',how='right')\n",
    "#\n",
    "lefts.join(rights,on='A',how='right').orderBy('A',ascending=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cf32b610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+\n",
      "|  A|  B|  C|  D|  F|  G|  H|\n",
      "+---+---+---+---+---+---+---+\n",
      "| A0| B0| C0| D0| B4| C4| D4|\n",
      "| A1| B1| C1| D1| B5| C5| D5|\n",
      "+---+---+---+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "leftp.merge(rightp,on='A',how='inner')\n",
    "#\n",
    "lefts.join(rights,on='A',how='inner').orderBy('A',ascending=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7cee1ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----+----+----+----+----+\n",
      "|  A|   B|   C|   D|   F|   G|   H|\n",
      "+---+----+----+----+----+----+----+\n",
      "| A0|  B0|  C0|  D0|  B4|  C4|  D4|\n",
      "| A1|  B1|  C1|  D1|  B5|  C5|  D5|\n",
      "| A2|  B2|  C2|  D2|null|null|null|\n",
      "| A3|  B3|  C3|  D3|null|null|null|\n",
      "| A6|null|null|null|  B6|  C6|  D6|\n",
      "| A7|null|null|null|  B7|  C7|  D7|\n",
      "+---+----+----+----+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "leftp.merge(rightp,on='A',how='outer')\n",
    "#\n",
    "lefts.join(rights,on='A',how='full').orderBy('A',ascending=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "88da6050",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [('a', 2, 3),\n",
    "           ('b', 5, 6),\n",
    "           ('c', 8, 9),\n",
    "           ('a', 2, 3),\n",
    "           ('b', 5, 6),\n",
    "           ('c', 8, 9)]\n",
    "col_name = ['col1', 'col2', 'col3']\n",
    "#\n",
    "dp = pd.DataFrame(my_list,columns=col_name)\n",
    "ds = spark.createDataFrame(my_list,schema=col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b6915147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+---------+\n",
      "|col1|min(col2)|avg(col3)|\n",
      "+----+---------+---------+\n",
      "|   a|        2|      3.0|\n",
      "|   b|        5|      6.0|\n",
      "|   c|        8|      9.0|\n",
      "+----+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dp.groupby(['col1']).agg({'col2':'min','col3':'mean'})\n",
    "#\n",
    "ds.groupBy(['col1']).agg({'col2': 'min', 'col3': 'avg'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6055dcde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+----+\n",
      "|col1|   2|   5|   8|\n",
      "+----+----+----+----+\n",
      "|   c|null|null|  18|\n",
      "|   b|null|  12|null|\n",
      "|   a|   6|null|null|\n",
      "+----+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pd.pivot_table(dp, values='col3', index='col1', columns='col2', aggfunc=np.sum)\n",
    "#\n",
    "ds.groupBy(['col1']).pivot('col2').sum('col3').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7b6c7790",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'A':['a','b','c','d'],'B':['m','m','n','n'],'C':[1,2,3,6]}\n",
    "dp = pd.DataFrame(d)\n",
    "ds = spark.createDataFrame(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "72bb2502",
   "metadata": {},
   "outputs": [],
   "source": [
    "d ={'Id':[1,2,3,4,5,6],\n",
    "    'Score': [4.00, 4.00, 3.85, 3.65, 3.65, 3.50]}\n",
    "#\n",
    "data = pd.DataFrame(d)\n",
    "dp = data.copy()\n",
    "ds = spark.createDataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9462646c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/02 19:51:55 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/04/02 19:51:55 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/04/02 19:51:55 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "+---+-----+----------------+----------+\n",
      "| Id|Score|Rank_spark_dense|Rank_spark|\n",
      "+---+-----+----------------+----------+\n",
      "|  1|  4.0|               1|         1|\n",
      "|  2|  4.0|               1|         1|\n",
      "|  3| 3.85|               2|         3|\n",
      "|  4| 3.65|               3|         4|\n",
      "|  5| 3.65|               3|         4|\n",
      "|  6|  3.5|               4|         6|\n",
      "+---+-----+----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dp['Rank_dense'] = dp['Score'].rank(method='dense',ascending =False)\n",
    "dp['Rank'] = dp['Score'].rank(method='min',ascending =False)\n",
    "dp\n",
    "#\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window\n",
    "w = Window.orderBy(ds.Score.desc())\n",
    "ds = ds.withColumn('Rank_spark_dense',F.dense_rank().over(w))\n",
    "ds = ds.withColumn('Rank_spark',F.rank().over(w))\n",
    "ds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef71f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
